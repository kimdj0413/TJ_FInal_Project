{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################\n",
    "##    뉴스 요약 트랜스포머 모델   ##\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 인코딩 타입 지정, 라이브러리 임포트, GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 전처리 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : [4079 1001  154  387 2215 1381   59 2765 3855   16 2507 3855  567 3855\n",
      "  101 2139  501 1904   19   60 1536 1001  154  387 2215  556    8   77\n",
      " 1348   91  653  537   59 2765 3855 1170   89  452   24  256   90    7\n",
      "   16  550    1   51  211  942 3282 3855   40   43  820  826    2 1844\n",
      "  279 1379   54 4060 3956 3980    3  567  399  536    6 2106 3855   75\n",
      "  960  536  168 2437   11  673  978 3898 1758  684  387  426 3876  706\n",
      "   19  228   82  106    3 3893 3888 2192 3855 1541 3855   28 3888 3890\n",
      " 3899 3855 1246  376 3587    2 2588 1459   16 2636 3855   12 2731  190\n",
      "   51  511  858  304    2  659    1   40   43  820  826    9   91  653\n",
      "  100    4 1380    7 1413 2404  288    2 1001  154  387 2215  556    4\n",
      "   59   15 1112 3413  111  256   90    7   16  550    1  474 1001    9\n",
      " 2731   26 1480  101  106   22    1   78  351 1043 3493   64 1243  158\n",
      "  875 3193 1704  894 2792   18  501  283   10  126  219 1101   26  101\n",
      "  106   22    1  909 3789  288  220  222   90 1428   17   19  172   24\n",
      " 1471  228  196   16  569   35  605  569    2  778   27 1372   15 1017\n",
      "  212 2555 2631  792  567   16 3869 4080    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "\n",
      "abs : [4079 1001  154  387 2215 1381 2866   13  567 2558 1348   91  653  537\n",
      " 1835    5 2805 3855   52  200    2   57  111 1540   91  399 1650 3855\n",
      " 1495    2  123  452   24  256   90    7   16  550 3869 4080    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "{'inputs': tf.int16, 'dec_inputs': tf.int16}\n",
      "{'outputs': tf.int16}\n"
     ]
    }
   ],
   "source": [
    "with open('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/pickle/sentences.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "with open('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/pickle/abs.pkl', 'rb') as f:\n",
    "    abs = pickle.load(f)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs':sentences,\n",
    "        'dec_inputs':abs[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs':abs[:, 1:]\n",
    "    }\n",
    "))\n",
    "\n",
    "print(f'sentence : {sentences[1]}')\n",
    "print(f'\\nabs : {abs[1]}')\n",
    "\n",
    "def convert_to_int16(inputs, outputs):\n",
    "    inputs = {key: tf.cast(value, tf.int16) for key, value in inputs.items()}\n",
    "    outputs = {key: tf.cast(value, tf.int16) for key, value in outputs.items()}\n",
    "    return inputs, outputs\n",
    "\n",
    "dataset = dataset.map(convert_to_int16)\n",
    "\n",
    "for batch in dataset.take(1):\n",
    "    print({key: value.dtype for key, value in batch[0].items()})\n",
    "    print({key: value.dtype for key, value in batch[1].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/문서요약 텍스트/Preprocess/tokenizer')\n",
    "\n",
    "SEN_MAX_LENGTH = 799\n",
    "ABS_MAX_LENGTH = 149\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "D_MODEL = 128\n",
    "NUM_LAYERS = 2  # 1로 바꿔보기\n",
    "NUM_HEADS = 2\n",
    "DFF = 256\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# D_MODEL = 256\n",
    "# NUM_LAYERS = 2\n",
    "# NUM_HEADS = 8\n",
    "# DFF = 512\n",
    "\n",
    "EPOCHS = 2000\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "warmup_steps = 1000\n",
    "previous_steps = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 트랜스포머 모델 빌드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    angle_rads = np.zeros(angle_rads.shape)\n",
    "    angle_rads[:, 0::2] = sines\n",
    "    angle_rads[:, 1::2] = cosines\n",
    "    pos_encoding = tf.constant(angle_rads)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "    print(pos_encoding.shape)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-3. 룩-어헤드 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4. 셀프 어텐션(스케일드 닷 프로덕트 어텐션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-5. 멀티헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-6. 인코더 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-7. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-8. 디코더 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-9. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "  \n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-10. 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) \n",
    "\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "  \n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-11. 모델 구조 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4081, 128)\n",
      "(1, 4081, 128)\n"
     ]
    }
   ],
   "source": [
    "model = transformer(\n",
    "  vocab_size=VOCAB_SIZE,\n",
    "  num_layers=NUM_LAYERS,\n",
    "  dff=DFF,\n",
    "  d_model=D_MODEL,\n",
    "  num_heads=NUM_HEADS,\n",
    "  dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 커스텀 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=1000, previous_steps=0):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "    self.previous_steps = previous_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    adjusted_step = step + self.previous_steps\n",
    "    arg1 = tf.math.rsqrt(adjusted_step)\n",
    "    arg2 = adjusted_step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "  \n",
    "learning_rate = CustomSchedule(D_MODEL, warmup_steps, previous_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 오차 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, ABS_MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 정확도 계산 함수 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, ABS_MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[acuuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  for i in range(ABS_MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "  print(f'원문 : {sentence}')\n",
    "  print(f'\\n요약 : {predicted_sentence}')\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 검증 데이터 준비 및 epoch 마다 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/문서요약 텍스트/Preprocess/finalPreprocess.csv')\n",
    "sentence = df['sentence']\n",
    "abs = df['abs']\n",
    "\n",
    "predict_sentence_1 = sentence[100]\n",
    "predict_sentence_2 = sentence[200]\n",
    "predict_abs_1 = abs[100]\n",
    "predict_abs_2 = abs[200]\n",
    "\n",
    "previous_loss = tf.Variable(float('inf'), trainable=False)\n",
    "\n",
    "class EpochValidation(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochPrint(epoch, logs)\n",
    "\n",
    "    def epochPrint(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"\\n***************  첫번째 예측  ***************\")\n",
    "            predict(predict_sentence_1)\n",
    "            print(f'\\n정답 : {predict_abs_1}')\n",
    "            print(\"\\n***************  두번째 예측  ***************\")\n",
    "            predict(predict_sentence_2)\n",
    "            print(f'\\n정답 : {predict_abs_2}')\n",
    "        \n",
    "        current_loss = logs.get('loss')\n",
    "        \n",
    "        if current_loss is not None:\n",
    "            if current_loss < previous_loss.numpy():\n",
    "                model.save_weights('D:/TJ_FInal_Project/KDJ/News_Summarization/Model/transformer.h5')\n",
    "                print(f'\\n손실 값 감소! 이전 손실: {previous_loss.numpy()}, 현재 손실: {current_loss}')\n",
    "            else:\n",
    "                print(f'\\n손실 값 증가 또는 동일')\n",
    "            \n",
    "            previous_loss.assign(current_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 모델 불러오기 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "***************  뉴스 기사 본문  ***************\n",
      "수면 대장내시경 중 환자 대장에 구멍(천공)을 낸 의사가 항소심에서도 유죄를 선고받았다. 이를 두고 의사들 사이에선 \"고의로 한 것도 아니고 노인의 장벽이 얇아 천공이 생기기 쉬운데, 어느 의사가 형사처벌을 감수하고 대장내시경 검사를 시행하려 하겠느냐\"며 비판의 목소리가 나왔다.  인천지법 형사5-1부(강부영 부장판사는) 업무상과실치상 혐의로 기소된 의사 A씨(74)의 항소를 기각하고 원심과 같은 금고 6개월에 집행유예 2년을 선고했다고 1일 밝혔다.  뉴스1에 따르면 A씨는 지난 2021년 4월12일 오전 9시10분쯤 자신이 운영하는 경기 부천시 내과의원에서 대장내시경을 받은 여성 B씨의 결장(대장 일부)에 천공(구멍)을 낸 뒤 적절한 조처를 하지 않은 혐의로 재판에 넘겨졌다.  B씨는 수면 대장내시경 이후 천공 합병증 등으로 복통을 호소했지만, A씨는 \"천공이 생기지 않았다\"고 판단했다.  A씨는 원심 재판장에서 \"대장내시경 검사 시 천공 합병증의 빈도가 0.8% 이하로 발생해 주의의무를 다해도 불가피하게 천공이 발생할 수 있다\"며 \"검사 후 B씨에게 엑스레이(X-ray) 검사도 실시했지만, 명확한 천공 소견이 발견되지 않아 퇴원 조치를 하는 등 필요한 조치를 모두 이행했다\"고 주장했다.  다만 법원은 A씨의 \"고령이면서 자궁적출 이력이 있는 B씨에게 장천공 발생 확률이 높고, 장에 내시경이 들어갈 때 조금 어려움이 있었다\"는 진술 등을 토대로 무리하게 내시경을 시도하다 천공을 발생시킨 것으로 봤다.  법원은 또 A씨가, B씨가 통증을 호소했을 때 복부·골반 부위에 대한 CT(컴퓨터단층촬영) 검사를 할 수 있는 병원으로 안내했어야 했기에 필요 조처를 했다고 보기 어렵다고 판단했다.  이에 불복한 A씨는 \"1심 판결이 너무 무거워서 부당하다\"며 항소심을 제기했지만, 법원은 A씨의 입장을 받아들이지 않았다.  재판부는 \"원심의 양형은 피고인에게 유·불리한 여러 정상을 충분히 고려 형을 정한 것으로 보인다\"며 \"다만 피고인이 이전까지 별다른 범죄 전력이 없는 초범인 점을 종합해 형을 내렸다\"고 양형 이유를 설명했다.  이에 대해 의사들 사이에선 \"의도한 게 아닌데도 의사가 죄인이 되는 상황을 만들어 법조계가 의료의 씨를 말린다\"는 목소리가 나온다. 의사 C씨는 \"구멍이 났는지 안 났는지로 판결할 게 아니라 구멍이 난 걸 알고도 방치했느냐 여부를 보고 판결했어야 한다\"며 \"노인은 원래 대장벽이 얇아 천공이 생기기 쉽다. 이런 걸로 형사 처벌하면 어느 내과의사가 대장내시경 검사를 하려 하겠느냐\"고 비판했다. 이 밖에도 \"이번 판결로 대장내시경으로 대장암 조기 검진하려는 어르신들은 검사받기가 더 힘들어질 것\"이라며 \"결국 대장암으로 진행하고 나서야 진단하란 말인가\"라는 반문도 나왔다.\n",
      "\n",
      "***************  요약  ***************\n",
      "원문 : 수면 대장내시경 중 환자 대장에 구멍을 낸 의사가 항소심에서도 유죄를 선고받았다. 이를 두고 의사들 사이에선 \"고의로 한 것도 아니고 노인의 장벽이 얇아 천공이 생기기 쉬운데, 어느 의사가 형사처벌을 감수하고 대장내시경 검사를 시행하려 하겠느냐\"며 비판의 목소리가 나왔다. 인천지법 형사5 1부 업무상과실치상 혐의로 기소된 의사 A씨의 항소를 기각하고 원심과 같은 금고 6개월에 집행유예 2년을 선고했다고 1일 밝혔다. 뉴스1에 따르면 A씨는 지난 2021년 4월12일 오전 9시10분쯤 자신이 운영하는 경기 부천시 내과의원에서 대장내시경을 받은 여성 B씨의 결장에 천공을 낸 뒤 적절한 조처를 하지 않은 혐의로 재판에 넘겨졌다. B씨는 수면 대장내시경 이후 천공 합병증 등으로 복통을 호소했지만, A씨는 \"천공이 생기지 않았다\"고 판단했다. A씨는 원심 재판장에서 \"대장내시경 검사 시 천공 합병증의 빈도가 0.8 이하로 발생해 주의의무를 다해도 불가피하게 천공이 발생할 수 있다\"며 \"검사 후 B씨에게 엑스레이 검사도 실시했지만, 명확한 천공 소견이 발견되지 않아 퇴원 조치를 하는 등 필요한 조치를 모두 이행했다\"고 주장했다. 다만 법원은 A씨의 \"고령이면서 자궁적출 이력이 있는 B씨에게 장천공 발생 확률이 높고, 장에 내시경이 들어갈 때 조금 어려움이 있었다\"는 진술 등을 토대로 무리하게 내시경을 시도하다 천공을 발생시킨 것으로 봤다. 법원은 또 A씨가, B씨가 통증을 호소했을 때 복부 골반 부위에 대한 CT 검사를 할 수 있는 병원으로 안내했어야 했기에 필요 조처를 했다고 보기 어렵다고 판단했다. 이에 불복한 A씨는 \"1심 판결이 너무 무거워서 부당하다\"며 항소심을 제기했지만, 법원은 A씨의 입장을 받아들이지 않았다. 재판부는 \"원심의 양형은 피고인에게 유 불리한 여러 정상을 충분히 고려 형을 정한 것으로 보인다\"며 \"다만 피고인이 이전까지 별다른 범죄 전력이 없는 초범인 점을 종합해 형을 내렸다\"고 양형 이유를 설명했다. 이에 대해 의사들 사이에선 \"의도한 게 아닌데도 의사가 죄인이 되는 상황을 만들어 법조계가 의료의 씨를 말린다\"는 목소리가 나온다. 의사 C씨는 \"구멍이 났는지 안 났는지로 판결할 게 아니라 구멍이 난 걸 알고도 방치했느냐 여부를 보고 판결했어야 한다\"며 \"노인은 원래 대장벽이 얇아 천공이 생기기 쉽다. 이런 걸로 형사 처벌하면 어느 내과의사가 대장내시경 검사를 하려 하겠느냐\"고 비판했다. 이 밖에도 \"이번 판결로 대장내시경으로 대장암 조기 검진하려는 어르신들은 검사받기가 더 힘들어질 것\"이라며 \"결국 대장암으로 진행하고 나서야 진단하란 말인가\"라는 반문도 나왔다.\n",
      "\n",
      "요약 : 수면 대장내시경 중 환자 대장에 구멍을 낸 의사가 항소심에서도 유죄를 선고받았으며 수면 대장내시경 검사를 시행하려 하겠느냐며 비판의 목소리가 나왔다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "***************  뉴스 기사 본문  ***************\n",
      "저비용항공사(LCC) 처음으로 파리 노선에 취항해 주목받았던 티웨이항공이 첫 귀국편에서부터 기체 결함으로 결항했다.  1일 항공업계에 따르면 지난달 28일 오후 8시30분(현지시각) 파리에서 인천으로 향할 예정이었던 TW402편이 기체 결함으로 인한 정비 이슈로 1시간30분가량 출발이 지연됐다.  하지만 정비 시간이 길어지면서 해당 항공편이 결항됐다. 티웨이항공이 대체편을 마련했으나 항공편을 예약한 승객 143명은 당초보다 21시간 이상 지연된 29일 오후 6시에야 파리를 떠날 수 있었다.  해당 여객기는 총 246석 규모 에어버스의 A330-200이다. 인천에서 출발한 항공편 탑승률은 98%를 기록했다.  티웨이항공 관계자는 \"유럽 노선을 포함해 현재 모든 노선의 더 안정적인 운영을 위해 안전에 집중적인 투자와 전사적 노력을 진행 중\"이라며 \"최상의 안전운항과 고객 만족을 위한 노력과 실천을 이어가겠다\"고 말했다.\n",
      "\n",
      "***************  요약  ***************\n",
      "원문 : 저비용항공사 처음으로 파리 노선에 취항해 주목받았던 티웨이항공이 첫 귀국편에서부터 기체 결함으로 결항했다. 1일 항공업계에 따르면 지난달 28일 오후 8시30분 파리에서 인천으로 향할 예정이었던 TW402편이 기체 결함으로 인한 정비 이슈로 1시간30분가량 출발이 지연됐다. 하지만 정비 시간이 길어지면서 해당 항공편이 결항됐다. 티웨이항공이 대체편을 마련했으나 항공편을 예약한 승객 143명은 당초보다 21시간 이상 지연된 29일 오후 6시에야 파리를 떠날 수 있었다. 해당 여객기는 총 246석 규모 에어버스의 A330 200이다. 인천에서 출발한 항공편 탑승률은 98 를 기록했다. 티웨이항공 관계자는 \"유럽 노선을 포함해 현재 모든 노선의 더 안정적인 운영을 위해 안전에 집중적인 투자와 전사적 노력을 진행 중\"이라며 \"최상의 안전운항과 고객 만족을 위한 노력과 실천을 이어가겠다\"고 말했다.\n",
      "\n",
      "요약 : 1일 항공업계에 따르면 지난달 28일 오후 8시30분 파리에서 인천으로 향할 예정이었던 TW402편이 기체 결함으로 인한 정비 이슈로 1시간30분가량 출발이 지연됐다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "***************  뉴스 기사 본문  ***************\n",
      "제10호 태풍 '산산'이 일본 남부 규슈에 상륙하면서 쏟아진 엄청난 양의 비로 4명이 숨지고 1명이 실종되는 등 인명피해가 속출했다. 또 전봇대가 무너지고 건물 외벽이 뜯기는 등 피해도 잇따랐다.  30일 일본 NHK에 따르면 태풍 산산으로 인해 현재까지 4명이 사망하고 1명이 실종됐으며 약 100여 명의 부상자가 발생했다.  구체적으로는 아이치현에서 산사태로 70대 부부와 30대 남성이 숨졌으며 가고시마시 가고시마항에서는 소형 선박을 타고 있던 남성 1명이 바다에 빠져 실종됐다.  항공편 결항도 이어지고 있으며 고속열차인 신칸센 규슈 노선도 일부 운행을 중단한 상태다. 규슈 지역 6개 현에서 262개 학교가 휴교하고 자동차 공장 14곳이 가동을 중단했다. 또 25만 가구에서 정전이 발생하기도 했다.  태풍 산산이 몰고 온 많은 비와 강풍으로 미야자키현 일부 지역엔 72시간 동안 평년 8월 한 달 강우량의 1.4배인 830㎜ 비가 내렸다.  이날까지 시코쿠 지역에는 최대 400㎜, 규슈와 도카이 지역은 300㎜ 이상의 많은 비가 쏟아질 전망이다.  태풍은 열도를 따라 천천히 이동하고 있어 피해는 더욱 커질 것으로 보인다. 산산은 진로를 동쪽으로 꺾어 이날 규슈 지역을 빠져나간 뒤, 오는 31일에는 오사카를 향할 것으로 예상된다.\n",
      "\n",
      "***************  요약  ***************\n",
      "원문 : 제10호 태풍 '산산'이 일본 남부 규슈에 상륙하면서 쏟아진 엄청난 양의 비로 4명이 숨지고 1명이 실종되는 등 인명피해가 속출했다. 또 전봇대가 무너지고 건물 외벽이 뜯기는 등 피해도 잇따랐다. 30일 일본 NHK에 따르면 태풍 산산으로 인해 현재까지 4명이 사망하고 1명이 실종됐으며 약 100여 명의 부상자가 발생했다. 구체적으로는 아이치현에서 산사태로 70대 부부와 30대 남성이 숨졌으며 가고시마시 가고시마항에서는 소형 선박을 타고 있던 남성 1명이 바다에 빠져 실종됐다. 항공편 결항도 이어지고 있으며 고속열차인 신칸센 규슈 노선도 일부 운행을 중단한 상태다. 규슈 지역 6개 현에서 262개 학교가 휴교하고 자동차 공장 14곳이 가동을 중단했다. 또 25만 가구에서 정전이 발생하기도 했다. 태풍 산산이 몰고 온 많은 비와 강풍으로 미야자키현 일부 지역엔 72시간 동안 평년 8월 한 달 강우량의 1.4배인 830 비가 내렸다. 이날까지 시코쿠 지역에는 최대 400 , 규슈와 도카이 지역은 300 이상의 많은 비가 쏟아질 전망이다. 태풍은 열도를 따라 천천히 이동하고 있어 피해는 더욱 커질 것으로 보인다. 산산은 진로를 동쪽으로 꺾어 이날 규슈 지역을 빠져나간 뒤, 오는 31일에는 오사카를 향할 것으로 예상된다.\n",
      "\n",
      "요약 : 제10호 태풍 '산산산'이 일본 남부 규슈에 상륙하면서 쏟아진 엄청난 양의 비로 4명이 숨지고 1명이 실종되는 등 인명피해가 속출했다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "***************  뉴스 기사 본문  ***************\n",
      "30일(현지 시각) 블룸버그는 “일본 기업이 통제하는 LNG 선적이 6시간마다 전 세계에서 출항한다”면서 “일본은 지난 반세기 동안 LNG 시장이 2500억 달러(약 334조원) 규모로 급속히 확대되는 데 중요한 역할을 했다”라고 보도했다. 일본은 한국처럼 자원 빈국으로 분류된다. 일본 정부는 이를 극복하기 위해 적극적으로 해외 자원 개발에 투자해 왔고, 그 결과 세계 최대 LNG 수입국에 올랐다. 일본은 연간 1억 톤 이상의 LNG를 수입하고, 세계 LNG 시장의 약 25% 물량을 처리하는 것으로 알려져 있다.  일본이 LNG 수입만 하는 것은 아니다. 블룸버그는 일본이 기술 제공과 금융 지원 등 종합 패키지를 통해 석탄에서 가스로 전환하려는 국가들의 중요한 파트너로 자리 잡았다고 설명했다. 일본의 엔지니어링 회사는 기술과 부품을 제공하고, 유틸리티 회사는 연료를 제공, 은행은 자금을 지원하는 식으로 LNG 산업에 깊숙이 관여하고 있다는 것이다.  호주 에너지 대기업 우드사이드 에너지 그룹의 전 최고경영자(CEO)인 피터 콜만은 “일본이 없었다면 LNG 산업은 지금과 같은 위치에 있을 수 없었을 것”이라며 “일본은 LNG 시장을 다각화하고 새로운 시장을 유치하려고 노력했다”라고 말했다.  일본이 LNG 강국이 되기까지 순탄했던 것은 아니다. 환경론자들은 끊임없이 천연가스가 지속 가능한 해결책이 아닐뿐더러 장기적으로 화석 연료 의존도를 고착화시킬 수 있다고 지적했다. 가스 산업의 메탄 배출이 기후에 큰 위협이 될 수 있다고 우려하기도 했다. 그러나 일본 당국자들은 LNG가 현실적인 에너지 전환을 위해 필요하다고 주장했으며 관련 사업에 대한 투자를 늘렸다.  2011년 후쿠시마 원전 사고 이후 LNG에 대한 투자를 지속해 온 일본은 전 세계적으로 LNG 사업을 확장했다. 그 결과 동남아시아와 같은 신흥 시장에서 에너지 수요가 증가하며 일본의 LNG 프로젝트가 중요한 역할을 하게 됐고, 일본 기업들은 막대한 자금을 거둬들였다. 블룸버그에 따르면 올해 1분기 일본의 기업들은 LNG 관련 사업에서 최소 140억 달러(약 19조원)의 이익을 냈다. 이는 일본 최대 가전 제조업체의 이익을 합친 것과 맞먹는 수준이라고 블룸버그는 설명했다.\n",
      "\n",
      "***************  요약  ***************\n",
      "원문 : 30일 블룸버그는 일본 기업이 통제하는 LNG 선적이 6시간마다 전 세계에서 출항한다 면서 일본은 지난 반세기 동안 LNG 시장이 2500억 달러 규모로 급속히 확대되는 데 중요한 역할을 했다 라고 보도했다. 일본은 한국처럼 자원 빈국으로 분류된다. 일본 정부는 이를 극복하기 위해 적극적으로 해외 자원 개발에 투자해 왔고, 그 결과 세계 최대 LNG 수입국에 올랐다. 일본은 연간 1억 톤 이상의 LNG를 수입하고, 세계 LNG 시장의 약 25 물량을 처리하는 것으로 알려져 있다. 일본이 LNG 수입만 하는 것은 아니다. 블룸버그는 일본이 기술 제공과 금융 지원 등 종합 패키지를 통해 석탄에서 가스로 전환하려는 국가들의 중요한 파트너로 자리 잡았다고 설명했다. 일본의 엔지니어링 회사는 기술과 부품을 제공하고, 유틸리티 회사는 연료를 제공, 은행은 자금을 지원하는 식으로 LNG 산업에 깊숙이 관여하고 있다는 것이다. 호주 에너지 대기업 우드사이드 에너지 그룹의 전 최고경영자인 피터 콜만은 일본이 없었다면 LNG 산업은 지금과 같은 위치에 있을 수 없었을 것 이라며 일본은 LNG 시장을 다각화하고 새로운 시장을 유치하려고 노력했다 라고 말했다. 일본이 LNG 강국이 되기까지 순탄했던 것은 아니다. 환경론자들은 끊임없이 천연가스가 지속 가능한 해결책이 아닐뿐더러 장기적으로 화석 연료 의존도를 고착화시킬 수 있다고 지적했다. 가스 산업의 메탄 배출이 기후에 큰 위협이 될 수 있다고 우려하기도 했다. 그러나 일본 당국자들은 LNG가 현실적인 에너지 전환을 위해 필요하다고 주장했으며 관련 사업에 대한 투자를 늘렸다. 2011년 후쿠시마 원전 사고 이후 LNG에 대한 투자를 지속해 온 일본은 전 세계적으로 LNG 사업을 확장했다. 그 결과 동남아시아와 같은 신흥 시장에서 에너지 수요가 증가하며 일본의 LNG 프로젝트가 중요한 역할을 하게 됐고, 일본 기업들은 막대한 자금을 거둬들였다. 블룸버그에 따르면 올해 1분기 일본의 기업들은 LNG 관련 사업에서 최소 140억 달러의 이익을 냈다. 이는 일본 최대 가전 제조업체의 이익을 합친 것과 맞먹는 수준이라고 블룸버그는 설명했다.\n",
      "\n",
      "요약 : 30일 블룸버그는 일본 기업이 통제하는 LNG 선적이 6시간마다 전 세계에서 출항한다고 밝혔으며 일본은 연간 1억 톤 이상의 LNG 시장의 약 25 물량을 처리하는 것으로 알려져 있다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "model.load_weights('D:/TJ_FInal_Project/KDJ/News_Summarization/Model/transformer.h5')\n",
    "\n",
    "def regex_column(columnList):\n",
    "  if not isinstance(columnList, str):                                                   # Nan을 빈 문자열로 대체\n",
    "      return ''\n",
    "  columnList = re.sub(r'\\S+@\\S+\\.\\S+', '', columnList)                                  # 이메일 삭제\n",
    "  columnList = columnList.replace('\\n', '')                                             # 개행 삭제\n",
    "  columnList = re.sub(r'\\[.*?\\]|\\{.*?\\}|\\(.*?\\)', '', columnList)                       # 소,중,대괄호 내용 삭제\n",
    "  columnList = re.sub(r'[^가-힣a-zA-Z0-9\\u4e00-\\u9fff\\s.,!?\\'\\\"~]', ' ', columnList)    # 이상한 특수문자 삭제\n",
    "  columnList = re.sub(r'\\s+', ' ', columnList).strip()                                  # 양 끝 공백 삭제\n",
    "  return columnList\n",
    "\n",
    "while True:\n",
    "  news_article = []\n",
    "\n",
    "  print(\"\\n뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\")\n",
    "  while True:\n",
    "      line = input()\n",
    "      if line == \"\":\n",
    "          break\n",
    "      news_article.append(line)\n",
    "\n",
    "  # 리스트를 문자열로 변환\n",
    "  news_article = \"\\n\".join(news_article)\n",
    "  regex_articel = regex_column(news_article)\n",
    "  print(\"***************  뉴스 기사 본문  ***************\")\n",
    "  print(news_article)\n",
    "  print(\"\\n***************  요약  ***************\")\n",
    "  predict(regex_articel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
