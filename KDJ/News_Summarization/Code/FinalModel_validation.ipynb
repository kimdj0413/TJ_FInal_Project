{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################\n",
    "##    뉴스 요약 트랜스포머 모델   ##\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 인코딩 타입 지정, 라이브러리 임포트, GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 전처리 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : [4079 1001  154  387 2215 1381   59 2765 3855   16 2507 3855  567 3855\n",
      "  101 2139  501 1904   19   60 1536 1001  154  387 2215  556    8   77\n",
      " 1348   91  653  537   59 2765 3855 1170   89  452   24  256   90    7\n",
      "   16  550    1   51  211  942 3282 3855   40   43  820  826    2 1844\n",
      "  279 1379   54 4060 3956 3980    3  567  399  536    6 2106 3855   75\n",
      "  960  536  168 2437   11  673  978 3898 1758  684  387  426 3876  706\n",
      "   19  228   82  106    3 3893 3888 2192 3855 1541 3855   28 3888 3890\n",
      " 3899 3855 1246  376 3587    2 2588 1459   16 2636 3855   12 2731  190\n",
      "   51  511  858  304    2  659    1   40   43  820  826    9   91  653\n",
      "  100    4 1380    7 1413 2404  288    2 1001  154  387 2215  556    4\n",
      "   59   15 1112 3413  111  256   90    7   16  550    1  474 1001    9\n",
      " 2731   26 1480  101  106   22    1   78  351 1043 3493   64 1243  158\n",
      "  875 3193 1704  894 2792   18  501  283   10  126  219 1101   26  101\n",
      "  106   22    1  909 3789  288  220  222   90 1428   17   19  172   24\n",
      " 1471  228  196   16  569   35  605  569    2  778   27 1372   15 1017\n",
      "  212 2555 2631  792  567   16 3869 4080    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "\n",
      "abs : [4079 1001  154  387 2215 1381 2866   13  567 2558 1348   91  653  537\n",
      " 1835    5 2805 3855   52  200    2   57  111 1540   91  399 1650 3855\n",
      " 1495    2  123  452   24  256   90    7   16  550 3869 4080    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "{'inputs': tf.int16, 'dec_inputs': tf.int16}\n",
      "{'outputs': tf.int16}\n"
     ]
    }
   ],
   "source": [
    "with open('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/pickle/sentences.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "with open('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/pickle/abs.pkl', 'rb') as f:\n",
    "    abs = pickle.load(f)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs':sentences,\n",
    "        'dec_inputs':abs[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs':abs[:, 1:]\n",
    "    }\n",
    "))\n",
    "\n",
    "print(f'sentence : {sentences[1]}')\n",
    "print(f'\\nabs : {abs[1]}')\n",
    "\n",
    "def convert_to_int16(inputs, outputs):\n",
    "    inputs = {key: tf.cast(value, tf.int16) for key, value in inputs.items()}\n",
    "    outputs = {key: tf.cast(value, tf.int16) for key, value in outputs.items()}\n",
    "    return inputs, outputs\n",
    "\n",
    "dataset = dataset.map(convert_to_int16)\n",
    "\n",
    "for batch in dataset.take(1):\n",
    "    print({key: value.dtype for key, value in batch[0].items()})\n",
    "    print({key: value.dtype for key, value in batch[1].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/문서요약 텍스트/Preprocess/tokenizer')\n",
    "\n",
    "SEN_MAX_LENGTH = 799\n",
    "ABS_MAX_LENGTH = 149\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "D_MODEL = 128\n",
    "NUM_LAYERS = 2  # 1로 바꿔보기\n",
    "NUM_HEADS = 2\n",
    "DFF = 256\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# D_MODEL = 256\n",
    "# NUM_LAYERS = 2\n",
    "# NUM_HEADS = 8\n",
    "# DFF = 512\n",
    "\n",
    "EPOCHS = 2000\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "warmup_steps = 1000\n",
    "previous_steps = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 트랜스포머 모델 빌드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    angle_rads = np.zeros(angle_rads.shape)\n",
    "    angle_rads[:, 0::2] = sines\n",
    "    angle_rads[:, 1::2] = cosines\n",
    "    pos_encoding = tf.constant(angle_rads)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "    print(pos_encoding.shape)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-3. 룩-어헤드 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4. 셀프 어텐션(스케일드 닷 프로덕트 어텐션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-5. 멀티헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-6. 인코더 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-7. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-8. 디코더 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-9. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "  \n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-10. 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) \n",
    "\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "  \n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-11. 모델 구조 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4081, 128)\n",
      "(1, 4081, 128)\n"
     ]
    }
   ],
   "source": [
    "model = transformer(\n",
    "  vocab_size=VOCAB_SIZE,\n",
    "  num_layers=NUM_LAYERS,\n",
    "  dff=DFF,\n",
    "  d_model=D_MODEL,\n",
    "  num_heads=NUM_HEADS,\n",
    "  dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 커스텀 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=1000, previous_steps=0):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "    self.previous_steps = previous_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    adjusted_step = step + self.previous_steps\n",
    "    arg1 = tf.math.rsqrt(adjusted_step)\n",
    "    arg2 = adjusted_step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "  \n",
    "learning_rate = CustomSchedule(D_MODEL, warmup_steps, previous_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 오차 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, ABS_MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 정확도 계산 함수 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, ABS_MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[acuuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  for i in range(ABS_MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "  print(f'원문 : {sentence}')\n",
    "  print(f'\\n요약 : {predicted_sentence}')\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 검증 데이터 준비 및 epoch 마다 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/TJ_FInal_Project/KDJ/News_Summarization/Data/문서요약 텍스트/Preprocess/finalPreprocess.csv')\n",
    "sentence = df['sentence']\n",
    "abs = df['abs']\n",
    "\n",
    "predict_sentence_1 = sentence[100]\n",
    "predict_sentence_2 = sentence[200]\n",
    "predict_abs_1 = abs[100]\n",
    "predict_abs_2 = abs[200]\n",
    "\n",
    "previous_loss = tf.Variable(float('inf'), trainable=False)\n",
    "\n",
    "class EpochValidation(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochPrint(epoch, logs)\n",
    "\n",
    "    def epochPrint(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"\\n***************  첫번째 예측  ***************\")\n",
    "            predict(predict_sentence_1)\n",
    "            print(f'\\n정답 : {predict_abs_1}')\n",
    "            print(\"\\n***************  두번째 예측  ***************\")\n",
    "            predict(predict_sentence_2)\n",
    "            print(f'\\n정답 : {predict_abs_2}')\n",
    "        \n",
    "        current_loss = logs.get('loss')\n",
    "        \n",
    "        if current_loss is not None:\n",
    "            if current_loss < previous_loss.numpy():\n",
    "                model.save_weights('D:/TJ_FInal_Project/KDJ/News_Summarization/Model/transformer.h5')\n",
    "                print(f'\\n손실 값 감소! 이전 손실: {previous_loss.numpy()}, 현재 손실: {current_loss}')\n",
    "            else:\n",
    "                print(f'\\n손실 값 증가 또는 동일')\n",
    "            \n",
    "            previous_loss.assign(current_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 모델 불러오기 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "한동훈 국민의힘 대표는 2일 이재명 더불어민주당 대표의 ‘계엄령 준비 의혹’ 제기에 대해 “근거를 제시하라”며 “사실이 아니라면 국기 문란에 해당한다”고 비판했다.  한 대표는 이날 국회에서 열린 최고위원회의에서 “11년 만에 열린 여야 대표 회담 모두발언에서 이 이야기가 나왔다”며 “이 정도면 민주당이 우리 모두 수긍할 만한 근거를 갖고 있을 것이라 생각한다”고 말했다.  이 대표는 전날 한 대표와의 회담 모두발언에서 “최근에 계엄 이야기가 자꾸 나온다”며 “종전에 만들어졌던 계엄안에 보면 계엄 해제를 국회가 요구하는 것을 막기 위해 국회의원들을 계엄 선포와 동시에 체포·구금하겠다는 계획을 꾸몄다는 이야기도 있다”고 말했다.  한 대표는 이에 “맞는다면 심각한 일 아닌가. 근거를 제시해 달라”며 “차차 알게 될 거다? 그것은 너무 무책임한 이야기다. 그것은 일종의 ‘내 귓속에 도청 장치가 있다’는 이야기와 다를 바 없다”고 지적했다.  이어 “이런 차원에서 제가 어제 면책특권 남용 제한을 법률로써 하자는 말씀을 드린 것”이라며 “지금 이 상황만 봐도 정치개혁의 필요성을 국민들이 충분히 느끼실 것”이라고 덧붙였다.  아울러 이 대표와의 회담 성과에 대해 “정치를 복원하고 민생 중심으로 정치하자고 의기투합한 것에 의미를 부여한다”며 “국민들께 그래도 정치는 계속된다는 것을 보여드리겠다는 것이 여야 대표가 했던 생각이다. 앞으로 자주 만나기로 했다”고 말했다.  한편 전날 대통령실도 이 대표의 ‘계엄령 준비’ 발언에 대해 “비상식적인 거짓 정치 공세”라며 “이런 거짓 정치 공세에 우리 국민께서 현혹되지 않길 바란다”고 밝혔다.\n",
      "\n",
      "***************  결과  ***************\n",
      "원문 : 한동훈 국민의힘 대표는 2일 이재명 더불어민주당 대표의 계엄령 준비 의혹 제기에 대해 근거를 제시하라 며 사실이 아니라면 국기 문란에 해당한다 고 비판했다. 한 대표는 이날 국회에서 열린 최고위원회의에서 11년 만에 열린 여야 대표 회담 모두발언에서 이 이야기가 나왔다 며 이 정도면 민주당이 우리 모두 수긍할 만한 근거를 갖고 있을 것이라 생각한다 고 말했다. 이 대표는 전날 한 대표와의 회담 모두발언에서 최근에 계엄 이야기가 자꾸 나온다 며 종전에 만들어졌던 계엄안에 보면 계엄 해제를 국회가 요구하는 것을 막기 위해 국회의원들을 계엄 선포와 동시에 체포 구금하겠다는 계획을 꾸몄다는 이야기도 있다 고 말했다. 한 대표는 이에 맞는다면 심각한 일 아닌가. 근거를 제시해 달라 며 차차 알게 될 거다? 그것은 너무 무책임한 이야기다. 그것은 일종의 내 귓속에 도청 장치가 있다 는 이야기와 다를 바 없다 고 지적했다. 이어 이런 차원에서 제가 어제 면책특권 남용 제한을 법률로써 하자는 말씀을 드린 것 이라며 지금 이 상황만 봐도 정치개혁의 필요성을 국민들이 충분히 느끼실 것 이라고 덧붙였다. 아울러 이 대표와의 회담 성과에 대해 정치를 복원하고 민생 중심으로 정치하자고 의기투합한 것에 의미를 부여한다 며 국민들께 그래도 정치는 계속된다는 것을 보여드리겠다는 것이 여야 대표가 했던 생각이다. 앞으로 자주 만나기로 했다 고 말했다. 한편 전날 대통령실도 이 대표의 계엄령 준비 발언에 대해 비상식적인 거짓 정치 공세 라며 이런 거짓 정치 공세에 우리 국민께서 현혹되지 않길 바란다 고 밝혔다.\n",
      "\n",
      "요약 : 한동훈 국민의힘 대표는 2일 이재명 더불어민주당 대표의 계엄령 준비 의혹 제기에 대해 근거를 제시하라 며 사실이 아니라면 국기 문란에 해당한다고 비판했다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "축제는 내달 5일 오후 1시부터 여의도 한강공원 인근에서 펼쳐진다. 오후 1시부터 7시까지는 한화그룹 계열사를 비롯한 다양한 회사들이 마련한 홍보부스에서 축제 분위기를 돋우는 프로모션과 이벤트를 진행할 예정이다.  본격적인 불꽃축제는 7시 개막식부터 시작된다. 첫 순서를 맡은 일본팀은 7시 20분부터 약 15분간 ‘더 하나비’를 주제로 ‘다채로운 공간예술’을 표현할 예정이다. 이어서 오후 7시 40분부터 미국팀은 '캘리포니아 드리밍'이라는 주제로 ‘자유와 꿈’을 표현할 예정이다.  오후 8시부터는 한국팀(한화)이 행사의 피날레를 장식할 예정이다. 올해 한화는 ‘플래시라이트’라는 테마 아래 ‘빛’을 모티브로 희망의 메시지를 담은 불꽃쇼를 선보인다.  특히 한화는 역대 최대 크기 불꽃 등을 연출해 더 많은 시민들이 멀리서도 불꽃을 볼 수 있도록 할 계획이다. 또한 글자와 숫자를 활용한 불꽃을 통해 스토리를 전달하고 원효대교를 활용한 불꽃 연출도 펼쳐진다.  불꽃의 감동을 더 크게 느낄 수 있는 공식 좌석도 운영한다. 해당 티켓은 LIFEPLUS TRIBES 앱에서 진행되는 골든티켓 이벤트를 통해 9월 2일부터 22일까지 신청이 가능하며, 오는 24일 당첨자를 발표한다. 자세한 정보는 서울세계불꽃축제 공식 홈페이지를 통해 확인할 수 있다.  또한 일부 공식 좌석에 대해서는 2일부터 티켓링크를 통해서 온라인 판매가 이뤄진다. 이번 유료 판매를 통한 수익은 관람객 안전시설과 편의시설 확충, 스마트앱을 활용한 안전관리 강화, 안전 인력 확충 등에 전액 재투자될 계획이다. 그 외에도 지역 상권 활성화를 위해 영등포구 ‘선유로운’ 로컬상권 상생 프로모션 등에 활용된다.  한화는 대규모 인파가 모이는 서울세계불꽃축제 특성을 고려해 작년 처음 도입한 스마트앱 ‘오렌지세이프티’를 한층 업그레이드해 안전관리시스템으로 운영한다. 통신사 연계를 통해 실시간으로 인파 밀집도를 측정하고 안전요원 배치현황을 파악하여 관람객들이 안전하게 축제를 즐길 수 있도록 분산을 유도할 계획이다.  또한 영등포구, 소방재난본부, 서울경찰청 등 유관기관과 종합상황실을 구축, 긴밀한 협조를 통해 신속한 대응이 가능하도록 하는 등 안전관리에 만전을 기한다.  현장 방문이 어려운 시민들도 불꽃축제의 감동을 그대로 느낄 수 있도록 온라인 생중계도 이뤄진다. 한화는 공식 유튜브 채널 ‘한화TV’를 통해서 여의도 불꽃쇼를 온라인으로 생중계하고 불꽃이 보이지만 음악이 들리지 않는 인근 지역에서는 스마트앱 ‘오렌지플레이’를 통해서 실시간 테마 음악 스트리밍 서비스를 제공할 예정이다.\n",
      "\n",
      "***************  결과  ***************\n",
      "원문 : 축제는 내달 5일 오후 1시부터 여의도 한강공원 인근에서 펼쳐진다. 오후 1시부터 7시까지는 한화그룹 계열사를 비롯한 다양한 회사들이 마련한 홍보부스에서 축제 분위기를 돋우는 프로모션과 이벤트를 진행할 예정이다. 본격적인 불꽃축제는 7시 개막식부터 시작된다. 첫 순서를 맡은 일본팀은 7시 20분부터 약 15분간 더 하나비 를 주제로 다채로운 공간예술 을 표현할 예정이다. 이어서 오후 7시 40분부터 미국팀은 '캘리포니아 드리밍'이라는 주제로 자유와 꿈 을 표현할 예정이다. 오후 8시부터는 한국팀이 행사의 피날레를 장식할 예정이다. 올해 한화는 플래시라이트 라는 테마 아래 빛 을 모티브로 희망의 메시지를 담은 불꽃쇼를 선보인다. 특히 한화는 역대 최대 크기 불꽃 등을 연출해 더 많은 시민들이 멀리서도 불꽃을 볼 수 있도록 할 계획이다. 또한 글자와 숫자를 활용한 불꽃을 통해 스토리를 전달하고 원효대교를 활용한 불꽃 연출도 펼쳐진다. 불꽃의 감동을 더 크게 느낄 수 있는 공식 좌석도 운영한다. 해당 티켓은 LIFEPLUS TRIBES 앱에서 진행되는 골든티켓 이벤트를 통해 9월 2일부터 22일까지 신청이 가능하며, 오는 24일 당첨자를 발표한다. 자세한 정보는 서울세계불꽃축제 공식 홈페이지를 통해 확인할 수 있다. 또한 일부 공식 좌석에 대해서는 2일부터 티켓링크를 통해서 온라인 판매가 이뤄진다. 이번 유료 판매를 통한 수익은 관람객 안전시설과 편의시설 확충, 스마트앱을 활용한 안전관리 강화, 안전 인력 확충 등에 전액 재투자될 계획이다. 그 외에도 지역 상권 활성화를 위해 영등포구 선유로운 로컬상권 상생 프로모션 등에 활용된다. 한화는 대규모 인파가 모이는 서울세계불꽃축제 특성을 고려해 작년 처음 도입한 스마트앱 오렌지세이프티 를 한층 업그레이드해 안전관리시스템으로 운영한다. 통신사 연계를 통해 실시간으로 인파 밀집도를 측정하고 안전요원 배치현황을 파악하여 관람객들이 안전하게 축제를 즐길 수 있도록 분산을 유도할 계획이다. 또한 영등포구, 소방재난본부, 서울경찰청 등 유관기관과 종합상황실을 구축, 긴밀한 협조를 통해 신속한 대응이 가능하도록 하는 등 안전관리에 만전을 기한다. 현장 방문이 어려운 시민들도 불꽃축제의 감동을 그대로 느낄 수 있도록 온라인 생중계도 이뤄진다. 한화는 공식 유튜브 채널 한화TV 를 통해서 여의도 불꽃쇼를 온라인으로 생중계하고 불꽃이 보이지만 음악이 들리지 않는 인근 지역에서는 스마트앱 오렌지플레이 를 통해서 실시간 테마 음악 스트리밍 서비스를 제공할 예정이다.\n",
      "\n",
      "요약 : 한화는 내달 5일 오후 1시부터 여의도 한강공원 인근에서 개최되는 '캘리포니아 드리밍'이라는 주제로 자유와 꿈 을 표현할 예정이며, 이번 유료 판매를 통한 수익은 관람객 안전관리 강화, 안전 인력 확충 등에 전액 재투자될 계획이다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "네이버가 이달부터 오는 11월까지 3개월간 소상공인(SME) 판매자들을 대상으로 네이버쇼핑 내 일부 버티컬 채널 유입 수수료를 감면하고 온라인 판촉을 지원한다. 최근 티메프 사태 등으로 위축된 이커머스(전자상거래) 시장 환경 속에서 SME 판매자들을 지원하겠다는 취지다.  네이버는 2일 패션타운 '소호&스트릿'·'디자이너', 네이버펫 '브랜드직영관' 등 3곳을 통해 상품이 판매될 경우 발생하는 채널 유입 수수료를 부과하지 않는다고 밝혔다.  네이버는 또 '네이버쇼핑 핫딜대전' 프로모션으로 SME 온라인 판로 확장을 지원하고 있다. 디지털, 가구, 생활, 패션, 뷰티, 식품 등 스마트스토어 판매자 상품 5000여개가 매주 기획전에서 소개되는 중이다. 네이버는 오는 12월까지 기획전 노출과 사용자 마케팅 등을 지원한다.  네이버는 업계에서 가장 빠른 대금 정산, 무료·교환 반품 비용 지원으로 SME 사업 환경을 개선하는 데 공을 들이고 있다. 2020년부터는 '네이버페이 빠른정산' 서비스를 도입해 배송 시작 다음 날 대금 100%를 정산해 SME 자금 순환을 지원한다. 그간 약 12만명의 SME에게 누적 기준 40조원이 넘는 대금을 선지급한 것.  네이버 도착보장 판매자에겐 '반품안심케어' 이용료를 지원하고 있다. 도착보장 판매자 70% 이상이 이를 통해 무료·교호나 반품 서비스를 제공 중이다.  이윤숙 네이버 쇼핑사업 부문장은 \"다소 침체된 최근의 이커머스 사업 환경에서 SME들이 안정적으로 비즈니스를 이어갈 수 있도록 지원하겠다\"고 말했다.\n",
      "\n",
      "***************  결과  ***************\n",
      "원문 : 네이버가 이달부터 오는 11월까지 3개월간 소상공인 판매자들을 대상으로 네이버쇼핑 내 일부 버티컬 채널 유입 수수료를 감면하고 온라인 판촉을 지원한다. 최근 티메프 사태 등으로 위축된 이커머스 시장 환경 속에서 SME 판매자들을 지원하겠다는 취지다. 네이버는 2일 패션타운 '소호 스트릿' '디자이너', 네이버펫 '브랜드직영관' 등 3곳을 통해 상품이 판매될 경우 발생하는 채널 유입 수수료를 부과하지 않는다고 밝혔다. 네이버는 또 '네이버쇼핑 핫딜대전' 프로모션으로 SME 온라인 판로 확장을 지원하고 있다. 디지털, 가구, 생활, 패션, 뷰티, 식품 등 스마트스토어 판매자 상품 5000여개가 매주 기획전에서 소개되는 중이다. 네이버는 오는 12월까지 기획전 노출과 사용자 마케팅 등을 지원한다. 네이버는 업계에서 가장 빠른 대금 정산, 무료 교환 반품 비용 지원으로 SME 사업 환경을 개선하는 데 공을 들이고 있다. 2020년부터는 '네이버페이 빠른정산' 서비스를 도입해 배송 시작 다음 날 대금 100 를 정산해 SME 자금 순환을 지원한다. 그간 약 12만명의 SME에게 누적 기준 40조원이 넘는 대금을 선지급한 것. 네이버 도착보장 판매자에겐 '반품안심케어' 이용료를 지원하고 있다. 도착보장 판매자 70 이상이 이를 통해 무료 교호나 반품 서비스를 제공 중이다. 이윤숙 네이버 쇼핑사업 부문장은 \"다소 침체된 최근의 이커머스 사업 환경에서 SME들이 안정적으로 비즈니스를 이어갈 수 있도록 지원하겠다\"고 말했다.\n",
      "\n",
      "요약 : 네이버는 2일 패션타운 '소호 스트릿' '디자이너', 네이버펫 '브랜드직영관' 등 3곳을 통해 상품이 판매될 경우 발생하는 채널 유입 수수료를 부과하지 않는다고 밝혔다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "머리를 다친 아이 상처 부위를 봉합해야 하는데 이를 받아주는 병원이 없어 반나절동안 발을 동동 구른 부모의 사연이 관심을 끌고 있다.  30개월 된 아이를 두고 있다는 지난달 31일 A 씨는 아이 머리를 꿰매야 하는데 마취과 의사가 없어 어렵다는 병원 안내에 따라 119에 전화를 걸었다. 수용이 가능한 병원을 알아보기 위해서였다.  하지만 몇 군데 병원에 연락을 해봐도 응급실에 받아줄 여력이 없거나 있다 하더라도 성인만 가능하지 영유아는 어렵다는 답변을 받았다.  대부분의 병원 응급실은 연락이 되지 않았고 힘들게 연락이 닿은 병원도 '(성형)외과, 마취과 전문의가 없다', '응급환자가 너무 많다' 등의 이유로 수용 불가를 통보했다.  A씨는 \"외국인인 아내는 '이럴 줄 알았으면 한국에 오지 않았다', '한국 의료 시스템이 이랬었냐'며 눈물을 흘렸다\"면서 \"예전에는 몇바늘 꿰매는 게 그다지 대수롭지 않은 일로 여겨졌었는데 왜 이렇게 힘든지 현실을 받아들이기가 어려웠다\"고 전했다.  주변에 있는 모든 병원에 연락을 돌린 지 몇시간 만에 한 병원에서 \"마취를 못해 아이가 힘들어할 텐데 참고할 수 있으면 해 주겠다\"는 답을 들었다.  A씨는 \"아이가 울고불고 고통스러워하는데, 움직이면 아이가 다치니 여러 명이 악착같이 잡고 있던 끝에 치료가 무사히 끝났다\"면서 \"병원에서는 지금 같은 상황에서 위급할 때는 119를 부르는 것 보다 보호자가 직접 환자를 데려가는 게 받아줄 확률이 더 높다고 하더라. 말로만 의료대란이라고 생각했지 막상 닥쳐보니 정말 심각한 게 느껴진다\"고 맺었다.  의대 입학정원 증원에 대한 반발로 전공의들 집단 사직이 이어지며 시작된 의정 갈등은 이달로 6개월째다. 응급실 대란은 이제 현실이 됐다. 앞서 김한규 더불어민주당 의원이 지난달 27일 YTN '뉴스온'에 출연해 \"아버지가 '응급실 뺑뺑이' 탓에 진료받지 못하고 세상을 떠났다\"며 의정 갈등 장기화로 인한 의료 공백을 비판했다.  별세한 김 의원 아버지는 이비인후과 전문의로, 제주시에서 오랫동안 병원을 운영해온 것으로 알려졌다.\n",
      "\n",
      "***************  결과  ***************\n",
      "원문 : 머리를 다친 아이 상처 부위를 봉합해야 하는데 이를 받아주는 병원이 없어 반나절동안 발을 동동 구른 부모의 사연이 관심을 끌고 있다. 30개월 된 아이를 두고 있다는 지난달 31일 A 씨는 아이 머리를 꿰매야 하는데 마취과 의사가 없어 어렵다는 병원 안내에 따라 119에 전화를 걸었다. 수용이 가능한 병원을 알아보기 위해서였다. 하지만 몇 군데 병원에 연락을 해봐도 응급실에 받아줄 여력이 없거나 있다 하더라도 성인만 가능하지 영유아는 어렵다는 답변을 받았다. 대부분의 병원 응급실은 연락이 되지 않았고 힘들게 연락이 닿은 병원도 '외과, 마취과 전문의가 없다', '응급환자가 너무 많다' 등의 이유로 수용 불가를 통보했다. A씨는 \"외국인인 아내는 '이럴 줄 알았으면 한국에 오지 않았다', '한국 의료 시스템이 이랬었냐'며 눈물을 흘렸다\"면서 \"예전에는 몇바늘 꿰매는 게 그다지 대수롭지 않은 일로 여겨졌었는데 왜 이렇게 힘든지 현실을 받아들이기가 어려웠다\"고 전했다. 주변에 있는 모든 병원에 연락을 돌린 지 몇시간 만에 한 병원에서 \"마취를 못해 아이가 힘들어할 텐데 참고할 수 있으면 해 주겠다\"는 답을 들었다. A씨는 \"아이가 울고불고 고통스러워하는데, 움직이면 아이가 다치니 여러 명이 악착같이 잡고 있던 끝에 치료가 무사히 끝났다\"면서 \"병원에서는 지금 같은 상황에서 위급할 때는 119를 부르는 것 보다 보호자가 직접 환자를 데려가는 게 받아줄 확률이 더 높다고 하더라. 말로만 의료대란이라고 생각했지 막상 닥쳐보니 정말 심각한 게 느껴진다\"고 맺었다. 의대 입학정원 증원에 대한 반발로 전공의들 집단 사직이 이어지며 시작된 의정 갈등은 이달로 6개월째다. 응급실 대란은 이제 현실이 됐다. 앞서 김한규 더불어민주당 의원이 지난달 27일 YTN '뉴스온'에 출연해 \"아버지가 '응급실 뺑뺑이' 탓에 진료받지 못하고 세상을 떠났다\"며 의정 갈등 장기화로 인한 의료 공백을 비판했다. 별세한 김 의원 아버지는 이비인후과 전문의로, 제주시에서 오랫동안 병원을 운영해온 것으로 알려졌다.\n",
      "\n",
      "요약 : 머리를 다친 아이 상처 부위를 봉합해야 하는데 이를 받아주는 병원이 없어 반나절동안 발을 동동 구른 부모의 사연이 관심을 끌고 있다.\n",
      "\n",
      "뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\n",
      "\n",
      "\n",
      "***************  결과  ***************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3608\\1071304054.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[0mnews_article\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_article\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m   \u001b[0mregex_articel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregex_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_article\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_article\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n***************  결과  ***************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m   \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex_articel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3608\\820249331.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   predicted_sentence = tokenizer.decode(\n\u001b[0;32m      5\u001b[0m       [i for i in prediction if i < tokenizer.vocab_size])\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3608\\3553335467.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTART_TOKEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mABS_MAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpredicted_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m                     )\n\u001b[0;32m   1105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# Node is not computable, try skipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                 for x_id, y in zip(\n",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m                     )\n\u001b[0;32m   1105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# Node is not computable, try skipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                 for x_id, y in zip(\n",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m                     )\n\u001b[0;32m   1105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# Node is not computable, try skipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                 for x_id, y in zip(\n",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m                     )\n\u001b[0;32m   1105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3608\\1540160089.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mscaled_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mscaled_attention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     concat_attention = tf.reshape(scaled_attention,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3608\\4113054617.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(query, key, value, mask)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mmatmul_qk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul_qk\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1002\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\G-10\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m       return cast_eager_fallback(\n\u001b[0;32m   2005\u001b[0m           x, DstT=DstT, Truncate=Truncate, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "model.load_weights('D:/TJ_FInal_Project/KDJ/News_Summarization/Model/transformer(202_0.89_0.22).h5')\n",
    "\n",
    "def regex_column(columnList):\n",
    "  if not isinstance(columnList, str):                                                   # Nan을 빈 문자열로 대체\n",
    "      return ''\n",
    "  columnList = re.sub(r'\\S+@\\S+\\.\\S+', '', columnList)                                  # 이메일 삭제\n",
    "  columnList = columnList.replace('\\n', '')                                             # 개행 삭제\n",
    "  columnList = re.sub(r'\\[.*?\\]|\\{.*?\\}|\\(.*?\\)', '', columnList)                       # 소,중,대괄호 내용 삭제\n",
    "  columnList = re.sub(r'[^가-힣a-zA-Z0-9\\u4e00-\\u9fff\\s.,!?\\'\\\"~]', ' ', columnList)    # 이상한 특수문자 삭제\n",
    "  columnList = re.sub(r'\\s+', ' ', columnList).strip()                                  # 양 끝 공백 삭제\n",
    "  return columnList\n",
    "\n",
    "while True:\n",
    "  news_article = []\n",
    "\n",
    "  print(\"\\n뉴스 기사를 입력하세요. 입력을 마치려면 enter을 입력하세요.\")\n",
    "  while True:\n",
    "      line = input()\n",
    "      if line == \"\":\n",
    "          break\n",
    "      news_article.append(line)\n",
    "\n",
    "  # 리스트를 문자열로 변환\n",
    "  news_article = \"\\n\".join(news_article)\n",
    "  regex_articel = regex_column(news_article)\n",
    "  print(news_article)\n",
    "  print(\"\\n***************  결과  ***************\")\n",
    "  predict(regex_articel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
